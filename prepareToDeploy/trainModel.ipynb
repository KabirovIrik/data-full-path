{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize, StandardScaler\n",
    "import joblib, pickle, random, csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = ['freq', 'query_results_count_num', 'len_mt', 'len_md', 'len_kw', 'len_w_mt', 'len_w_md', 'len_w_kw', 'words_count', 'words_count_sw', 'spamity', 'max_spam', 'water_content', 'tf_idf', 'density']\n",
    "target_cols = ['pos', 'real_pos', 'page', 'is_first_page']\n",
    "cols_to_analyze = ['spamity', 'water_content', 'tf_idf', 'density']\n",
    "df = pd.read_csv('df_to_model_source.csv', sep=';')\n",
    "queries = df['search_query_n'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transliterate(name):\n",
    "    \"\"\"\n",
    "    Автор: LarsKort\n",
    "    Дата: 16/07/2011; 1:05 GMT-4;\n",
    "    Не претендую на \"хорошесть\" словарика. В моем случае и такой пойдет,\n",
    "    вы всегда сможете добавить свои символы и даже слова. Только\n",
    "    это нужно делать в обоих списках, иначе будет ошибка.\n",
    "    \"\"\"\n",
    "    # Слоаврь с заменами\n",
    "    slovar = {'а':'a','б':'b','в':'v','г':'g','д':'d','е':'e','ё':'yo',\n",
    "      'ж':'zh','з':'z','и':'i','й':'i','к':'k','л':'l','м':'m','н':'n',\n",
    "      'о':'o','п':'p','р':'r','с':'s','т':'t','у':'u','ф':'f','х':'h',\n",
    "      'ц':'c','ч':'ch','ш':'sh','щ':'sch','ъ':'','ы':'y','ь':'','э':'e',\n",
    "      'ю':'u','я':'ya', 'А':'A','Б':'B','В':'V','Г':'G','Д':'D','Е':'E','Ё':'YO',\n",
    "      'Ж':'ZH','З':'Z','И':'I','Й':'I','К':'K','Л':'L','М':'M','Н':'N',\n",
    "      'О':'O','П':'P','Р':'R','С':'S','Т':'T','У':'U','Ф':'F','Х':'H',\n",
    "      'Ц':'C','Ч':'CH','Ш':'SH','Щ':'SCH','Ъ':'','Ы':'y','Ь':'','Э':'E',\n",
    "      'Ю':'U','Я':'YA',',':'','?':'',' ':'_','~':'','!':'','@':'','#':'',\n",
    "      '$':'','%':'','^':'','&':'','*':'','(':'',')':'','-':'','=':'','+':'',\n",
    "      ':':'',';':'','<':'','>':'','\\'':'','\"':'','\\\\':'','/':'','№':'',\n",
    "      '[':'',']':'','{':'','}':'','ґ':'','ї':'', 'є':'','Ґ':'g','Ї':'i',\n",
    "      'Є':'e', '—':''}\n",
    "        \n",
    "    # Циклически заменяем все буквы в строке\n",
    "    for key in slovar:\n",
    "        name = name.replace(key, slovar[key])\n",
    "    return name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_per_q = dict()\n",
    "for query in queries:\n",
    "    df_query = df[df['search_query_n'] == query]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df_query[feat_cols], \n",
    "        df_query['is_first_page'], # is_first_page, page\n",
    "        test_size=0.3, \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    \n",
    "    RF = RandomForestClassifier(n_estimators=200, max_depth=15, random_state=42) # binary\n",
    "    RF.fit(X_train, y_train)\n",
    "    pred_rf = RF.predict(X_test)\n",
    "\n",
    "    \n",
    "    models_per_q[query] = dict()\n",
    "    filename = transliterate(query)+'.sav'\n",
    "    models_per_q[query]['model'] = filename\n",
    "    joblib.dump(RF, '../app/'+filename)\n",
    "    \n",
    "\n",
    "    models_per_q[query]['borders'] = {\n",
    "        col:[df_query[df_query['page'] == 0][col].describe()['25%'], \n",
    "             df_query[df_query['page'] == 0][col].describe()['75%']] \n",
    "        for col in cols_to_analyze\n",
    "    }\n",
    "a_file = open(\"../app/query_dict_data.pkl\", \"wb\")\n",
    "pickle.dump(models_per_q, a_file)\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
